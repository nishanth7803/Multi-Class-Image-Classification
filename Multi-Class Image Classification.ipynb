{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-27T13:07:43.504298Z",
     "iopub.status.busy": "2022-09-27T13:07:43.503933Z",
     "iopub.status.idle": "2022-09-27T13:07:48.375775Z",
     "shell.execute_reply": "2022-09-27T13:07:48.374804Z",
     "shell.execute_reply.started": "2022-09-27T13:07:43.504266Z"
    }
   },
   "source": [
    "**This is a problem where you will be given images of plant seedling belonging to 12 different classes and your model should be able to predict to which class the test images belong to. You can get this dataset from [here](http://www.kaggle.com/competitions/plant-seedlings-classification)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**I'm using TRANSFER LEARNING technique to tackle this problem. To achive this, we will be importing and loading a pre-trained model(about which you can refer [here](http://keras.io/api/applications/inceptionresnetv2/) and it's weights and then we remove the top layer of the pre-trained model and then add some fully connected layers and output layers according to our requirment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let us start by importing the required libraries and model. I'm using [InceptionResNetV2](http://keras.io/api/applications/inceptionresnetv2/) model. You are free to choose any pre-trained model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:26:08.756402Z",
     "iopub.status.busy": "2022-09-29T05:26:08.755513Z",
     "iopub.status.idle": "2022-09-29T05:26:08.787297Z",
     "shell.execute_reply": "2022-09-29T05:26:08.786382Z",
     "shell.execute_reply.started": "2022-09-29T05:26:08.755847Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:26:10.072699Z",
     "iopub.status.busy": "2022-09-29T05:26:10.072341Z",
     "iopub.status.idle": "2022-09-29T05:26:15.373187Z",
     "shell.execute_reply": "2022-09-29T05:26:15.372122Z",
     "shell.execute_reply.started": "2022-09-29T05:26:10.072669Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "# I'm importing preprocess_input function to preprocess our image data \n",
    "# before passing it to the model for it's better understanding and performance.\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:26:16.422090Z",
     "iopub.status.busy": "2022-09-29T05:26:16.421465Z",
     "iopub.status.idle": "2022-09-29T05:26:16.431273Z",
     "shell.execute_reply": "2022-09-29T05:26:16.429432Z",
     "shell.execute_reply.started": "2022-09-29T05:26:16.422053Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now I'm importing ImageDataGenerator to read the images and for data augmentation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:26:17.815618Z",
     "iopub.status.busy": "2022-09-29T05:26:17.814893Z",
     "iopub.status.idle": "2022-09-29T05:26:17.820450Z",
     "shell.execute_reply": "2022-09-29T05:26:17.819446Z",
     "shell.execute_reply.started": "2022-09-29T05:26:17.815582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now I'm specifying the paths to the directories where our train and test images are present\n",
    "train_path = '../input/seedlings/plant-seedlings-classification/train'\n",
    "test_path = '../input/seedlings/plant-seedlings-classification/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:26:19.137321Z",
     "iopub.status.busy": "2022-09-29T05:26:19.136550Z",
     "iopub.status.idle": "2022-09-29T05:26:19.145100Z",
     "shell.execute_reply": "2022-09-29T05:26:19.144186Z",
     "shell.execute_reply.started": "2022-09-29T05:26:19.137281Z"
    }
   },
   "outputs": [],
   "source": [
    "# I'm using a keras functional API model in this problem as it is more flexible compared to\n",
    "# keras sequential model\n",
    "from tensorflow.keras.models import Model\n",
    "# Now I'm importing the required layes\n",
    "from tensorflow.keras.layers import Dense,Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:26:21.457059Z",
     "iopub.status.busy": "2022-09-29T05:26:21.456673Z",
     "iopub.status.idle": "2022-09-29T05:26:29.910092Z",
     "shell.execute_reply": "2022-09-29T05:26:29.909112Z",
     "shell.execute_reply.started": "2022-09-29T05:26:21.457021Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 05:26:21.568415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 05:26:21.692078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 05:26:21.692904: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 05:26:21.694616: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-29 05:26:21.694939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 05:26:21.695643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 05:26:21.696326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 05:26:24.054255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 05:26:24.055232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 05:26:24.055955: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-29 05:26:24.056577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_resnet_v2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 1s 0us/step\n",
      "219070464/219055592 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# initializing our model with the model's base as pre-trained model\n",
    "# Giving the include_top parameter a false to remove the top layer of the pre-trained model\n",
    "# weights = 'imagenet' stands for keeping the original weights of the model\n",
    "base_model = InceptionResNetV2(include_top=False,input_shape=(299,299,3),weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:26:31.027169Z",
     "iopub.status.busy": "2022-09-29T05:26:31.026781Z",
     "iopub.status.idle": "2022-09-29T05:26:31.055701Z",
     "shell.execute_reply": "2022-09-29T05:26:31.054733Z",
     "shell.execute_reply.started": "2022-09-29T05:26:31.027136Z"
    }
   },
   "outputs": [],
   "source": [
    "# This step makes sure that the base_model does not update its weights during training.\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now we will be building a model of our own with few layers on the top of the pre-trained model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now, I will be passing the output we recieve by training our data on the pre trained model to the next layers which we built. The key advantage of this is that we train our data on the base_model only once and we pass that output as input to the layers which we built on the base_model, rather than once per epoch. It is a lot more cheaper and faster**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But remember - By doing this,  it doesn't allow you to dynamically modify the input data of your new model during training, which is required when doing data augmentation. So for very small datasets, where data augmentation is very important, this approach doesn't go well**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:26:35.547465Z",
     "iopub.status.busy": "2022-09-29T05:26:35.547095Z",
     "iopub.status.idle": "2022-09-29T05:26:35.560956Z",
     "shell.execute_reply": "2022-09-29T05:26:35.556671Z",
     "shell.execute_reply.started": "2022-09-29T05:26:35.547434Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now I'm passing the output of the base_model as input to flatten layer, which falttens out \n",
    "# the dimensions of tensord to 1-D array.\n",
    "flatten_layer = Flatten()(base_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:26:37.635877Z",
     "iopub.status.busy": "2022-09-29T05:26:37.635504Z",
     "iopub.status.idle": "2022-09-29T05:26:37.666867Z",
     "shell.execute_reply": "2022-09-29T05:26:37.665736Z",
     "shell.execute_reply.started": "2022-09-29T05:26:37.635844Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now I'm adding fully-connected layers(Dense Layers)\n",
    "dense_layer_1 = Dense(256,activation='relu')(flatten_layer)\n",
    "dense_layer_2 = Dense(128,activation='relu')(dense_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:26:40.702922Z",
     "iopub.status.busy": "2022-09-29T05:26:40.702558Z",
     "iopub.status.idle": "2022-09-29T05:26:40.718436Z",
     "shell.execute_reply": "2022-09-29T05:26:40.717443Z",
     "shell.execute_reply.started": "2022-09-29T05:26:40.702891Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now adding an output layer with 12 neurons as our data has images belonging to 12 classes\n",
    "# This layer predicts to which class the image belongs to\n",
    "prediction_layer = Dense(12,activation='softmax')(dense_layer_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can learn more about activation functions[ here](http://keras.io/api/layers/activations/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:26:48.367420Z",
     "iopub.status.busy": "2022-09-29T05:26:48.366970Z",
     "iopub.status.idle": "2022-09-29T05:26:48.434201Z",
     "shell.execute_reply": "2022-09-29T05:26:48.433242Z",
     "shell.execute_reply.started": "2022-09-29T05:26:48.367382Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now I'm creating the final model and compiling it to train our data.\n",
    "model = Model(inputs=base_model.input,outputs=prediction_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To compile our model, I'm using adam optimizer and loss as categorical_crossentropy which works well with multi-class image classification. You can learn more about them [here](http://keras.io/api/optimizers/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:26:52.351146Z",
     "iopub.status.busy": "2022-09-29T05:26:52.350755Z",
     "iopub.status.idle": "2022-09-29T05:26:52.376326Z",
     "shell.execute_reply": "2022-09-29T05:26:52.375375Z",
     "shell.execute_reply.started": "2022-09-29T05:26:52.351112Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:26:55.715415Z",
     "iopub.status.busy": "2022-09-29T05:26:55.713387Z",
     "iopub.status.idle": "2022-09-29T05:26:55.720640Z",
     "shell.execute_reply": "2022-09-29T05:26:55.719700Z",
     "shell.execute_reply.started": "2022-09-29T05:26:55.715372Z"
    }
   },
   "outputs": [],
   "source": [
    "# I'm not passing many command inside of ImageDataGenerator \n",
    "# This is because, as I mentioned, this method doesn't effectively augment our data\n",
    "train_img_gen = ImageDataGenerator(rescale=1./255,horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:26:58.295797Z",
     "iopub.status.busy": "2022-09-29T05:26:58.295434Z",
     "iopub.status.idle": "2022-09-29T05:26:59.435474Z",
     "shell.execute_reply": "2022-09-29T05:26:59.434258Z",
     "shell.execute_reply.started": "2022-09-29T05:26:58.295765Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4750 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "# reading the input using flow_from_directory method with a batch size of 32 images per batch\n",
    "# I have passed target size as (299,299) as InceptionResNetV2 works well with (299,299,3)\n",
    "train_images = train_img_gen.flow_from_directory(train_path,batch_size=32,\n",
    "                                                target_size=(299,299),class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:27:03.198165Z",
     "iopub.status.busy": "2022-09-29T05:27:03.197769Z",
     "iopub.status.idle": "2022-09-29T05:40:03.563675Z",
     "shell.execute_reply": "2022-09-29T05:40:03.562665Z",
     "shell.execute_reply.started": "2022-09-29T05:27:03.198132Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 05:27:04.789905: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 05:27:16.855320: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/149 [==============================] - 140s 823ms/step - loss: 3.4385 - accuracy: 0.5295\n",
      "Epoch 2/10\n",
      "149/149 [==============================] - 68s 452ms/step - loss: 0.9229 - accuracy: 0.7556\n",
      "Epoch 3/10\n",
      "149/149 [==============================] - 68s 455ms/step - loss: 0.4880 - accuracy: 0.8522\n",
      "Epoch 4/10\n",
      "149/149 [==============================] - 68s 459ms/step - loss: 0.3082 - accuracy: 0.9034\n",
      "Epoch 5/10\n",
      "149/149 [==============================] - 67s 451ms/step - loss: 0.2249 - accuracy: 0.9269\n",
      "Epoch 6/10\n",
      "149/149 [==============================] - 67s 447ms/step - loss: 0.1801 - accuracy: 0.9402\n",
      "Epoch 7/10\n",
      "149/149 [==============================] - 66s 446ms/step - loss: 0.1419 - accuracy: 0.9522\n",
      "Epoch 8/10\n",
      "149/149 [==============================] - 67s 452ms/step - loss: 0.1557 - accuracy: 0.9488\n",
      "Epoch 9/10\n",
      "149/149 [==============================] - 68s 454ms/step - loss: 0.1474 - accuracy: 0.9512\n",
      "Epoch 10/10\n",
      "149/149 [==============================] - 69s 462ms/step - loss: 0.1287 - accuracy: 0.9573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5d490d6650>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now It is time to train our model.\n",
    "model.fit(train_images,epochs=10,steps_per_epoch=len(train_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now I'm reading in the test images to run our model and predict to which class they belong to**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:40:37.109986Z",
     "iopub.status.busy": "2022-09-29T05:40:37.109625Z",
     "iopub.status.idle": "2022-09-29T05:40:37.115843Z",
     "shell.execute_reply": "2022-09-29T05:40:37.114061Z",
     "shell.execute_reply.started": "2022-09-29T05:40:37.109957Z"
    }
   },
   "outputs": [],
   "source": [
    "test_img_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:40:47.528670Z",
     "iopub.status.busy": "2022-09-29T05:40:47.527942Z",
     "iopub.status.idle": "2022-09-29T05:40:48.049480Z",
     "shell.execute_reply": "2022-09-29T05:40:48.048406Z",
     "shell.execute_reply.started": "2022-09-29T05:40:47.528632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 794 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_images = test_img_gen.flow_from_directory(test_path,batch_size=1,\n",
    "                                              target_size=(299,299),class_mode='categorical',\n",
    "                                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:40:51.802783Z",
     "iopub.status.busy": "2022-09-29T05:40:51.802120Z",
     "iopub.status.idle": "2022-09-29T05:41:23.304211Z",
     "shell.execute_reply": "2022-09-29T05:41:23.303214Z",
     "shell.execute_reply.started": "2022-09-29T05:40:51.802749Z"
    }
   },
   "outputs": [],
   "source": [
    "# this command returns the probabilities of an image belonging to each calss\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:41:27.325893Z",
     "iopub.status.busy": "2022-09-29T05:41:27.324860Z",
     "iopub.status.idle": "2022-09-29T05:41:27.332302Z",
     "shell.execute_reply": "2022-09-29T05:41:27.331314Z",
     "shell.execute_reply.started": "2022-09-29T05:41:27.325843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(794, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have 794 images belonging to 12 classes in test directory.\n",
    "# So shape of our prediction array should be (794,12)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:41:29.176438Z",
     "iopub.status.busy": "2022-09-29T05:41:29.176083Z",
     "iopub.status.idle": "2022-09-29T05:41:29.184667Z",
     "shell.execute_reply": "2022-09-29T05:41:29.183705Z",
     "shell.execute_reply.started": "2022-09-29T05:41:29.176409Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.45693952e-17, 5.04031981e-08, 5.97395633e-10, ...,\n",
       "        4.04844615e-14, 1.00000000e+00, 4.19060245e-18],\n",
       "       [2.82539446e-07, 7.56660630e-13, 1.01753085e-11, ...,\n",
       "        1.37918567e-13, 2.80611987e-14, 6.99295811e-07],\n",
       "       [2.08533146e-09, 6.45526063e-11, 1.68918712e-06, ...,\n",
       "        1.52710852e-12, 8.46909365e-15, 9.98142481e-01],\n",
       "       ...,\n",
       "       [7.74813325e-10, 9.04298247e-10, 2.43781342e-05, ...,\n",
       "        5.11886866e-10, 7.03230216e-15, 9.99948740e-01],\n",
       "       [4.22043356e-15, 9.84586835e-01, 1.54098514e-02, ...,\n",
       "        3.24243319e-06, 9.58365760e-08, 2.22792162e-12],\n",
       "       [1.26538402e-09, 6.08205084e-11, 8.36964553e-10, ...,\n",
       "        6.68809539e-16, 1.07062970e-11, 9.29133073e-12]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now in the following steps, I'm converting our predictions into a dataframe, where ecah image is assigned with a class to which it belongs to. This is done by assigning the class with highest probability to our image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:41:33.595198Z",
     "iopub.status.busy": "2022-09-29T05:41:33.594820Z",
     "iopub.status.idle": "2022-09-29T05:41:33.600910Z",
     "shell.execute_reply": "2022-09-29T05:41:33.599673Z",
     "shell.execute_reply.started": "2022-09-29T05:41:33.595166Z"
    }
   },
   "outputs": [],
   "source": [
    "species = [\"Black-grass\", \"Charlock\", \"Cleavers\", \"Common Chickweed\", \"Common wheat\", \n",
    "           \"Fat Hen\",\"Loose Silky-bent\", \"Maize\", \"Scentless Mayweed\", \"Shepherds Purse\",\n",
    "           \"Small-flowered Cranesbill\",\"Sugar beet\"]\n",
    "\n",
    "classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:41:37.251971Z",
     "iopub.status.busy": "2022-09-29T05:41:37.251600Z",
     "iopub.status.idle": "2022-09-29T05:41:37.260450Z",
     "shell.execute_reply": "2022-09-29T05:41:37.259237Z",
     "shell.execute_reply.started": "2022-09-29T05:41:37.251938Z"
    }
   },
   "outputs": [],
   "source": [
    "# identifying the highest probability and assiging it as the class to our image\n",
    "for i in range(0, 794):\n",
    "    x = predictions[i, :].argmax(axis=0)\n",
    "    classes += [species[x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:41:40.186627Z",
     "iopub.status.busy": "2022-09-29T05:41:40.186267Z",
     "iopub.status.idle": "2022-09-29T05:41:40.209936Z",
     "shell.execute_reply": "2022-09-29T05:41:40.208931Z",
     "shell.execute_reply.started": "2022-09-29T05:41:40.186597Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "final_df['file'] = test_images.filenames\n",
    "final_df['file'] = final_df['file'].str.replace('test/', '')\n",
    "final_df['species'] = classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-29T05:41:43.321430Z",
     "iopub.status.busy": "2022-09-29T05:41:43.321050Z",
     "iopub.status.idle": "2022-09-29T05:41:43.339904Z",
     "shell.execute_reply": "2022-09-29T05:41:43.338948Z",
     "shell.execute_reply.started": "2022-09-29T05:41:43.321398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0021e90e4.png</td>\n",
       "      <td>Small-flowered Cranesbill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>003d61042.png</td>\n",
       "      <td>Fat Hen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007b3da8b.png</td>\n",
       "      <td>Sugar beet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0086a6340.png</td>\n",
       "      <td>Common Chickweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00c47e980.png</td>\n",
       "      <td>Sugar beet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00d090cde.png</td>\n",
       "      <td>Loose Silky-bent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00ef713a8.png</td>\n",
       "      <td>Common Chickweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>01291174f.png</td>\n",
       "      <td>Fat Hen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>026716f9b.png</td>\n",
       "      <td>Loose Silky-bent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>02cfeb38d.png</td>\n",
       "      <td>Black-grass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>03566743d.png</td>\n",
       "      <td>Shepherds Purse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>03a2ee656.png</td>\n",
       "      <td>Small-flowered Cranesbill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>03e322a29.png</td>\n",
       "      <td>Sugar beet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>03ef36742.png</td>\n",
       "      <td>Scentless Mayweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>043449b0b.png</td>\n",
       "      <td>Sugar beet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0437393b1.png</td>\n",
       "      <td>Fat Hen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>04814f36d.png</td>\n",
       "      <td>Scentless Mayweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>05341a8a6.png</td>\n",
       "      <td>Scentless Mayweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>060450d79.png</td>\n",
       "      <td>Common Chickweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>060f1dc84.png</td>\n",
       "      <td>Shepherds Purse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0625f063b.png</td>\n",
       "      <td>Common Chickweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>063363305.png</td>\n",
       "      <td>Small-flowered Cranesbill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>06d12f6fa.png</td>\n",
       "      <td>Shepherds Purse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>071cb3ece.png</td>\n",
       "      <td>Sugar beet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0751c0bbc.png</td>\n",
       "      <td>Sugar beet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>07e62f903.png</td>\n",
       "      <td>Maize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>085974290.png</td>\n",
       "      <td>Scentless Mayweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0885e7690.png</td>\n",
       "      <td>Scentless Mayweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>089ad62a7.png</td>\n",
       "      <td>Charlock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>08d591441.png</td>\n",
       "      <td>Sugar beet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0911d3dee.png</td>\n",
       "      <td>Scentless Mayweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>099b961ec.png</td>\n",
       "      <td>Shepherds Purse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0a64e3e6c.png</td>\n",
       "      <td>Loose Silky-bent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0ad9e7dfb.png</td>\n",
       "      <td>Maize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0ae6668fa.png</td>\n",
       "      <td>Loose Silky-bent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0bf7bfb05.png</td>\n",
       "      <td>Loose Silky-bent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0c27cf05f.png</td>\n",
       "      <td>Loose Silky-bent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0c4199daa.png</td>\n",
       "      <td>Loose Silky-bent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0c45ace27.png</td>\n",
       "      <td>Common Chickweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0c51bf229.png</td>\n",
       "      <td>Maize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0c5f6c493.png</td>\n",
       "      <td>Loose Silky-bent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0caeda5df.png</td>\n",
       "      <td>Common wheat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0d117d910.png</td>\n",
       "      <td>Common Chickweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0d31e6602.png</td>\n",
       "      <td>Small-flowered Cranesbill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0dba99002.png</td>\n",
       "      <td>Sugar beet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0e8492cb1.png</td>\n",
       "      <td>Sugar beet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0ebf8f2f4.png</td>\n",
       "      <td>Maize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0ee4ad224.png</td>\n",
       "      <td>Scentless Mayweed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0f6cbe5e8.png</td>\n",
       "      <td>Maize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0fb233ad6.png</td>\n",
       "      <td>Small-flowered Cranesbill</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file                    species\n",
       "0   0021e90e4.png  Small-flowered Cranesbill\n",
       "1   003d61042.png                    Fat Hen\n",
       "2   007b3da8b.png                 Sugar beet\n",
       "3   0086a6340.png           Common Chickweed\n",
       "4   00c47e980.png                 Sugar beet\n",
       "5   00d090cde.png           Loose Silky-bent\n",
       "6   00ef713a8.png           Common Chickweed\n",
       "7   01291174f.png                    Fat Hen\n",
       "8   026716f9b.png           Loose Silky-bent\n",
       "9   02cfeb38d.png                Black-grass\n",
       "10  03566743d.png            Shepherds Purse\n",
       "11  03a2ee656.png  Small-flowered Cranesbill\n",
       "12  03e322a29.png                 Sugar beet\n",
       "13  03ef36742.png          Scentless Mayweed\n",
       "14  043449b0b.png                 Sugar beet\n",
       "15  0437393b1.png                    Fat Hen\n",
       "16  04814f36d.png          Scentless Mayweed\n",
       "17  05341a8a6.png          Scentless Mayweed\n",
       "18  060450d79.png           Common Chickweed\n",
       "19  060f1dc84.png            Shepherds Purse\n",
       "20  0625f063b.png           Common Chickweed\n",
       "21  063363305.png  Small-flowered Cranesbill\n",
       "22  06d12f6fa.png            Shepherds Purse\n",
       "23  071cb3ece.png                 Sugar beet\n",
       "24  0751c0bbc.png                 Sugar beet\n",
       "25  07e62f903.png                      Maize\n",
       "26  085974290.png          Scentless Mayweed\n",
       "27  0885e7690.png          Scentless Mayweed\n",
       "28  089ad62a7.png                   Charlock\n",
       "29  08d591441.png                 Sugar beet\n",
       "30  0911d3dee.png          Scentless Mayweed\n",
       "31  099b961ec.png            Shepherds Purse\n",
       "32  0a64e3e6c.png           Loose Silky-bent\n",
       "33  0ad9e7dfb.png                      Maize\n",
       "34  0ae6668fa.png           Loose Silky-bent\n",
       "35  0bf7bfb05.png           Loose Silky-bent\n",
       "36  0c27cf05f.png           Loose Silky-bent\n",
       "37  0c4199daa.png           Loose Silky-bent\n",
       "38  0c45ace27.png           Common Chickweed\n",
       "39  0c51bf229.png                      Maize\n",
       "40  0c5f6c493.png           Loose Silky-bent\n",
       "41  0caeda5df.png               Common wheat\n",
       "42  0d117d910.png           Common Chickweed\n",
       "43  0d31e6602.png  Small-flowered Cranesbill\n",
       "44  0dba99002.png                 Sugar beet\n",
       "45  0e8492cb1.png                 Sugar beet\n",
       "46  0ebf8f2f4.png                      Maize\n",
       "47  0ee4ad224.png          Scentless Mayweed\n",
       "48  0f6cbe5e8.png                      Maize\n",
       "49  0fb233ad6.png  Small-flowered Cranesbill"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can have a smaple look at first 50 predictions!!!\n",
    "final_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Whooo!!! Now, we have successfully built a model to achieve multi-class image classification**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
